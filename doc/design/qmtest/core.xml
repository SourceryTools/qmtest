<?xml version="1.0"?>
<!--

  File:   core.xml
  Author: Mark Mitchell, Greg Wilson, Alex Samuel
  Date:   2000-11-01

  Contents:
    Core architecture of qmtest.

  Copyright (C) 2000 CodeSourcery LLC.  This material may
  be distributed only subject to the terms and conditions set forth in
  the Software Carpentry Open Publication License, which is available at:

    http://www.software-carpentry.com/openpub-license.html

-->
<chapter id="concepts"><title>Concepts</title>

 <section><title>Overview</title>

 <para>This section described the core concepts and architecture of
 &qmtest;.  Although this material is intendend primarily for
 implementors, these concepts described here are for the most part
 exposed to users.  The entities that are described in this chapter
 are precisely the entities that users will manipulate on a regular
 basis.</para>

 </section>

 <section><title>Terminology</title>

 <section><title>Roles</title>

 <para>An <firstterm>author</firstterm> is someone who writes tests.
 A <firstterm>tester</firstterm> is someone who runs tests.  Most
 authors are also testers, but many testers will run tests they did
 not write themselves (particularly when using third-party or open
 source software).</para>

 </section>

 <section><title>Test Specifications</title>

  <para>An individual <firstterm>test</firstterm> is an entity that,
  when run, produces a single <link linkend="concept-outcome">outcome</link>
  indicating success or failure.  A test consists of:
   <orderedlist>
    <listitem>
     <para>A <firstterm>test ID</firstterm> that uniquely identifies
     the test in the test database.</para>
    </listitem>

    <listitem>
     <para>A reference to a single <firstterm>test class</firstterm>,
     which defines how the test is executed.</para>
    </listitem>

    <listitem>
     <para>A list of <firstterm> arguments</firstterm> that are used
     to construct particular tests.</para>
    </listitem>

    <listitem>
     <para>A set of one or more <firstterm>
     properties</firstterm>, which provide extra information about the
     test.</para>
    </listitem>

    <listitem>
     <para><firstterm>Prerequisite tests</firstterm>, whose outcomes
     must be known before this test can be executed.</para>
    </listitem>
  
    <listitem>
     <para>Optional <firstterm>setup</firstterm> and
     <firstterm>cleanup</firstterm> steps.</para>
    </listitem>

   </orderedlist>
  </para>

 <section><title>Test Identifiers</title>

  <para>A <firstterm>test ID</firstterm> is a string that identifies a
  test.  Every test must have a unique ID within the database that
  contains it.</para>

  <para>A test's ID is constructed by concatenating its name with the
  ID of the suite that contains it, using "." as a concatenator.
  Suite IDs are constructed similarly.  Each field in the name may
  contain one or more digits, lower-case letters, or an underscore.
  Thus, test IDs are strings like
  <literal>stream.output.unable_to_open_file_for_writing</literal>.
  These restrictions allow safe, easy mapping of test IDs into the
  filesystem.  Test IDs and suite IDs are in separate namespaces;
  every test database implementation must allow users to create a test
  and a test suite with the same ID.</para>

 </section>

 <section><title>Test Classes</title>

  <para>A <firstterm>test class</firstterm> defines how a particular
  type of test is created and run.  Each test class corresponds to a
  Python class with the same name that contains code to execute the
  test and to interpret the result of that execution.</para>

 </section>
 
 <section><title>Arguments</title>

  <para>A test is instantiated by providing the
  <firstterm>Arguments</firstterm> to the constructor for the test
  class.  The resulting object is a test.  Each test argument is a
  single Python expression, represented as a string.</para>

 </section>

 <section><title>Properties</title>

  <para><firstterm>Properties</firstterm> are name/value pairs
  used to provide extra information about tests, such as their
  "weight", the operating system(s) on which it makes sense to run the
  test, and so on.</para>

 </section>

 <section><title>Prerequisites</title>

  <para>If a test A is a prerequisite of a test B, then B is only run
  if A produces a particular result.  Normally, if A is a prerequisite
  of B, then B will only be run if A succeeds.  &qmtest; also allows
  users to specify that B is to be run unless there was an error in
  A.</para>

 </section>

 <section><title>Setup and Cleanup Actions</title>

 <para>If an individual test requires setup or cleanup, then the test
 clsas itself will handle the necessary actions.  However, on
 occasion, setup or cleanup actions will be required for a large group
 of tests.  A test can therefore specify any number of
 <firstterm>actions</firstterm>, by providing a list of action IDs.
 Each action ID identifies an instance of an action class.  Each
 action class provides a method that performs necessary setups, and
 another method that performs necessary cleanups.  The setups are
 executed at some point before the test is run; the cleanups are
 executed afterwards.  If any of the setups indicate failure, the test
 is not run; it's <link linkend="concept-outcome">outcome</link> will
 be <literal>UNTESTED</literal>.</para>

 </section>

 </section>

 <section><title>Test Execution</title>

 <section id="concept-outcome"><title>Outcomes</title>

  <para>The outcome of a test indicates whether it passed, failed, or
  whether some exceptional situation occurred.  In particular, there
  are four test outcomes:
   <itemizedlist>
    <listitem>
     <para><literal>PASS</literal>: the test succeeded.</para>
    </listitem>

    <listitem>
     <para><literal>FAIL</literal>: the test failed.</para>
    </listitem>

    <listitem>
     <para><literal>ERROR</literal>: a problem occurred in the test
     execution environment, rather than in the tested software.  For
     example, this outcome is used when the test class wanted to
     spawn a process containing an executable in order to test it, but
     could not because the system call to create a new process failed.
     </para>
    </listitem>

    <listitem>
     <para><literal>UNTESTED</literal>: &qmtest; did not attempt to
     execute the test.  For example, this outcome is used when
     &qmtest; determines that one of the prerequisites failed.</para>
    </listitem>
   </itemizedlist>
  </para>

 </section>

 <section id="concept-result"><title>Results</title>
  
  <para>A <firstterm>result</firstterm> contains information about the
  execution of a single test.  Each test result contains the test's
  id, a test outcome, the time at which the test was executed, and
  zero or more <firstterm>properties</firstterm>.  These may include
  such things as the reason why a particular test was untested, or the
  values of environment variables when the test was run.</para>

 </section>

 </section>

 <section><title>Test Aggregation</title>

 <section><title>Test Suite</title>

  <para>A <firstterm>test suite</firstterm> is a collection of tests
  and other test suites.  Test suites are used to aggregate reporting
  of results, as in "17 out of 22 graph traversal tests reported
  errors".  Test suites are also used to specify which tests to
  re-run, as in "execute all I/O tests". </para>

 </section>

 <section id="concept-database"><title>Test Database</title>

 <para>A <firstterm>test database</firstterm> stores test and
 test-suite specifications.  The test database is responsible for
 obtaining the test instance associated with a particular test id, or
 for obtaining the test instances that make up a particular suite.
 Although much of the subsequent discussion refers to a particular
 implementation of the test database (which places test specifications
 in the filesystem), &qmtest; allows for the substitution of
 alternative test datbase implementations.  Such implementations might
 dynamically generate test specifications, or extract them from source
 code, or perform other similar manipulations.</para>

 </section>

 </section>

 <section><title>&qmtest; Components</title>

 <section><title>Execution Engine</title>

  <para>The <firstterm>execution engine</firstterm> is responsible for
  executing tests, as well as for collecting and recording the
  results.</para>

 </section>

 <section id="concept-iface"><title>User Interface</title>

 <para>The <firstterm>user interface</firstterm> is responsible for
 taking commands from the user regarding which tests to run and
 presenting this information to the engine.  The user interface is
 also responsible for presenting reports to the user containing
 summaries of the results.</para>

 </section>

 </section>

 </section>

 <section id="concept-default-database">
 <title>Test Database: Default Implementation</title>

 <para>The <link linkend="concept-database">test database</link> is
 responsible for mapping test IDs to test instances.  The way in which
 a test database does this will differ on the database in use, and
 much of the power of &qmtest; comes from the ability to provide
 specialized test databases.  This section describes the default
 testbase implementation provided with &qmtest;.  The next section
 provides an example of a specialized test database that could be used
 to deal with test specifications in a form other than provided
 here.</para>

 <section><title>Data Storage</title>

 <para>The physical database will consist of a directory in the
 filesystem, together with its subdirectories and the files contained
 in all of these directories.  Each file within this directory
 hierarchy that ends with the extension <filename>.qmt</filename>
 contains exactly one test specification.  The file whose path is
 given by <filename>foo/bar/baz.qmt</filename> relative to the root of
 the database will have the test ID <filename>foo.bar.baz</filename>.
 (By using a particular extension for test files, desktop environments
 can associate particular icons with test files.  Using a particular
 extension, together with the requirement that there be only one test
 per file, means that both locating a particular test in the database
 and enumerating all the tests in the database are speedy
 operations.)</para>

 </section>

 <section><title>Test Specifications</title>

 <para>The test specifications themselves will be represented as XML,
 using the following DTD:
    <programlisting>
<![CDATA[
<!ELEMENT test
    ( class, 
      ( argument | category | prerequisite | preaction | postaction )* 
    )
>

<!ELEMENT class (#PCDATA)>

<!ELEMENT argument (#PCDATA)>
<!ATTLIST argument
    name CDATA #REQUIRED
    type ( expression | text ) #IMPLIED
>

<!ELEMENT category (#PCDATA)>

<!ELEMENT prerequisite (#PCDATA)>

<!ELEMENT preaction (#PCDATA)>

<!ELEMENT postaction (#PCDATA)>
]]>
    </programlisting>
 </para>

 <para>For example, suppose that Diana Dowhile's compiler crashes when given
 the following input:
   <programlisting>
int main ()
{
  volatile int x = 2;
  return x - 2;
}   
   </programlisting>
 Diana determines that the test case causes the compiler to crash only
 when the <literal>-fpic</literal> flag is provided to the compiler.
 Diana might write the following test-specification:
   <programlisting>
<![CDATA[
<?xml version="1.0"?>
<&qmtest;.test>
 <class>Compile</class>
 <argument name="input" type="text">
<![CDATA[
int main ()
{
  volatile int x = 2;
  return x - 2;
}]]>
]]&gt;<![CDATA[
 </argument>
 <argument name="flags">'-fpic'</argument>
 <category>C</category>
 <category>PIC</category>
</&qmtest;.test>
]]>
   </programlisting>
  This specification indicates that the test class to be used is the
  <literal>Compile</literal> class.  This class takes two arguments:
  the text of a program to compile, and the flags to use when
  compiling the test program.  When the instance is executed, the
  program test will be written to a temporary file, and the compiler
  will be run.  The test specification also indicates that the test is
  in two particular categories.  The "C" categorization indicates that
  this test is written in the C programming language; if Diana wishes
  to test only C, as opposed to C++ or Fortran programs, she could
  indicate that by asking &qmtest; to run only those tests in the "C"
  category.  The "PIC" categorization indicates that the test tests
  the <literal>-fpic</literal> option; after a change to the code that
  deals with this option, she could choose to rerun only those tests
  in the "PIC" category.
  </para>

 </section>

 <section><title>Test Classes</title>
 
 <para>Each test specification indicates a test class.  In order to
 instantiate an instance of that test class, the database must locate
 the Python code for that test class.  The test database will search
 for a corresponding <filename>.py</filename> or
 <filename>.pyc</filename> file in the following directories in order
 to find the test class:
 <itemizedlist>
   <listitem>
     <para>The directories provided in the
     <literal>QMTEST_CLASSPATH</literal> environment variable.  This
     environment variable will use the same syntax as the
     <literal>PATH</literal> environment variable on the system on
     which &qmtest; is running.</para>
   </listitem>

   <listitem>
     <para>The directory containing the test specification, and its
        parents in the directory hierarchy, stopping at the directory
        that forms the root of the test database.</para>
   </listitem>

   <listitem>
     <para>Those directories containing standard test classes provided
     by &qmtest;.</para>
   </listitem>
 </itemizedlist>
 Note that the directories in the <literal>PYTHONPATH</literal>
 environment variable is not searched, so as to avoid accidentally
 interpreting ordinary Python classes as test classes.
 </para>

 </section>

 <section><title>Suites</title>

 <para>As mentioned above, each subdirectory of the test database is
 implicitly considered a test suite.  Thus, if there is a directory
 in Diana's database named <literal>parser</literal>, she can run all
 the test in this subdirectory (and the subdirectories within it) by
 asking &qmtest; to run the <literal>parser</literal> suite.</para>

 <para>However, test suites do not always naturally form a tree.  (See
 the <link linkend="req-suites">test suite requirements</link>
 chapter.)  Users may specify suites in addition to those provided
 implicitly by the database by creating files with the
 <filename>.qms</filename> extension.  Each such file contains the
 names of tests, given relative to the directory containing the
 <filename>.qms</filename> file.  The ID for a test suite is computed
 in the precisely the same way as the ID for a test.  In fact, note
 that a test and a test suite may have the same ID.</para>

 </section>

 </section>

 <section><title>Test Database: Custom Implementation</title>

 <para>In this section, we show how &qmtest; meets the <link
 linkend="req-spec">requirement</link> that users be able to execute
 tests specified in formats other than &qmtest;'s default XML
 format.</para>

 <para>In particular, by creating a specialized test database, Diana
 can reuse <link linkend="story-diana">an extant test suite</link>,
 which consists of C source code with special comments that indicate
 the command-line flags to use when executing particular tests.</para>

 <para>Most of the behavior specified by the default test database
 implementation will work as is, but Diana needs to modify the
 function that maps test IDs to test instances.  Rather than search
 for a <filename>.qmt</filename>, Diana needs to search for a
 <filename>.c</filename> file.  Instead of finding XML in the file
 describing the test, she must extract the arguments to the
 <literal>Compile</literal> test class from the special comments in
 the file.  Diana will create her specialized test database class by
 inheriting from the standard class and overriding a method or two.
 Then, by using this alternative test database class, Diana can use
 &qmtest;'s superior execution and reporting capabilities to execute
 her extant tests.</para>

 </section>

 <section><title>Supplied Test Classes</title>

 <para>Although users may of course implement customized test classes,
 &qmtest; provides several test classes that users can use directly,
 without writing any Python code.  The first of these is the
 <classname>ExitCode</classname> class.  This class accepts as
 arguments the name of a program and arguments to provide the program.
 The test passes if the program exits with code zero, and fails if a
 non-zero exit code is returned, or if the program receives a fatal
 signal.  The exit code, as well as any output produced by the program
 on the standard output or standard error streams, is recorded in the
 <link linkend="concept-result">result</link> for the indicated test.
 This basic test class can be used to test a wide variety of
 command-line programs.</para>

 <para>&qmtest; also provides a <classname>Difference</classname> test
 class.  This test class accepts as arguments the name of a program,
 arguments to provide the program, and the expected output of the
 program as a regular expression.  The test passes if the tested
 program produces the expected output when executed.  A variety of
 options are provided to allow for cases in which some parts of the
 output are expected to vary.  For example, the expected output can be
 provided as a regular expression.</para>

 <para>The set of supplied test classes will grow as additional common
 testing paradigms are identified.</para>

 </section>

 <section><title>Expected Outcomes</title>

 <para>One of the &qmtest; <link
 linkend="req-expected">requirements</link> section is that users must
 be able to indicate that a particular test is presently expected to
 fail.  Under most circumstances, that information is best kept with
 the test specification itself.  On the other hand, users may
 sometimes want to use an alternative set of expected outcomes.  In
 particular, allowing the use of an alternative set of expected
 outcomes allows users to use <link linkend="req-reference">reference
 results</link>.</para>

 <para>Therefore, &qmtest; allows the specification of expected
 outcomes both in the test specification itself, and in an external
 file.  Because the comparision of a particular outcome with the <link
 linkend="concept-iface">user interface</link>, the details of the
 formats used has not yet been finalized.</para>
 
 </section>

 <section><title>Results Management</title>

 <para>&qmtest; stores the results of test suite runs in XML data
 files.  These files are not part of the test database and are not
 automatically managed in any way by &qmtest;.  Users are free to use
 whatever archiving or version control software they choose to store
 these files over time.  Because the manipulation of these files is
 part of the <link linkend="concept-iface">user interface</link>, the
 details of the format used has not yet been finalized.</para>

 </section>

</chapter>

<!--
  Local Variables:
  mode: sgml
  indent-tabs-mode: nil
  sgml-indent-step: 1 
  sgml-always-quote-attributes: t
  sgml-general-insert-case: lower
  sgml-minimize-attributes: nil
  sgml-parent-document: ("qmtest.xml" "book" "chapter")
  End:
-->
