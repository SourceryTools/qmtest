<?xml version="1.0"?>
<!--

  File:   index.xhtml
  Author: Mark Mitchell, Greg Wilson, Alex Samuel
  Date:   2000-11-01

  Contents:
    Master file for qmtest design document.

  Copyright (C) 2000 CodeSourcery LLC.  This material may
  be distributed only subject to the terms and conditions set forth in
  the Software Carpentry Open Publication License, which is available at:

    http://www.software-carpentry.com/openpub-license.html

-->
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.1.2//EN"
[
  <!-- Internal DTD subset.  Only entities should be defined here. -->

  <!-- Commonly-used symbols, terms, and abbreviations specific to
  this document.  -->

  <!ENTITY qmbuild "QMBuild">
  <!ENTITY qmtest "QMTest">

  <!ENTITY sc "&#60;ulink url=&#34;http://www.software-carpentry.com&#34;&#62;Software Carpentry&#60;/ulink&#62;">

  <!-- Each chapter is contained in a separate file, and included by
  entity reference.  -->

  <!ENTITY req.xml SYSTEM "req.xml">
  <!ENTITY core.xml SYSTEM "core.xml">
  <!ENTITY impl.xml SYSTEM "impl.xml">
]>
<book>
 <bookinfo>
  <title>&qmtest; Design</title>
  <author>
   <firstname>Mark</firstname>
   <surname>Mitchell</surname>
  </author>
  <author>
   <firstname>Greg</firstname>
   <surname>Wilson</surname>
  </author>
  <author>
   <firstname>Alex</firstname>
   <surname>Samuel</surname>
  </author>
 </bookinfo>

 <chapter><title>Introduction</title>

  <para>Most programmers don't do enough testing today because:
   <itemizedlist>
    <listitem>
     <para>They aren't required to.</para>
    </listitem>

    <listitem>
     <para>It's tedious.</para>
    </listitem>

    <listitem>
     <para>Existing tools are hard to use, expensive, and don't
     actually provide much help.</para>
    </listitem>

    <listitem>
     <para>They don't know where to start, when to stop, or how to
     tell whether the tests they've written are
     meaningful.</para>
    </listitem>
   </itemizedlist>
  </para>

  <para>Software tools cannot solve the first problem, but
  &qmtest; tries to solve the second by addressing the third and
  fourth. In particular:
   <itemizedlist>
    <listitem>
     <para>&qmtest; has a gentle learning curve, especially for
     developers without software engineering training. &qmtest; does
     this by:
     <itemizedlist>
     <listitem>
      <para>being very simple to install and configure;</para>
     </listitem>

     <listitem>
      <para>making it very easy for developers to create an empty
      (skeletal) testsuite for a project;</para>
     </listitem>

     <listitem>
      <para>making it equally easy for developers to create the first
      real test for a project, or to add another test once N tests
      have been written.</para>
     </listitem>
     </itemizedlist>
     </para>
    </listitem>

    <listitem>
     <para>&qmtest; provides a very simple workflow, so that tests can
     easily and systematically be added, modified, inspected, and
     summarized by developers, managers, and other
     stakeholders.</para>
    </listitem>

    <listitem>
     <para>&qmtest; provides feedback regarding the quality and
     thoroughness of testing so that developers will be able to tell
     how much they have done, how much remains to be done, and how
     well third party modules have been tested.</para>
    </listitem>
   </itemizedlist>
  </para>

  <para>Some of the particular scenarios that &qmtest; handles are:
   <itemizedlist>
    <listitem>
     <para>Static unit testing of functions, classes, and modules in
     languages such as C, Python, and Java. (These three languages are
     chosen as examples because they span the range from low-level to
     high-level.)</para>
    </listitem>

    <listitem>
     <para>Customizable reporting of test results, ranging from a
     single-line command-line summary of the number of tests that
     passed and failed, through to automatic creation of charts of
     test statistics over time.</para>
    </listitem>

    <listitem>
     <para>Scriptable control of testsuite execution, so that portions
     can be executed selectively, executed repeatedly under different
     load conditions, only executed at certain times of day, and so
     on.</para>
    </listitem>

    <listitem>
     <para>Parallel execution of testsuites.</para>
    </listitem>
   </itemizedlist>
  </para>

  <para>This document begins by describing <link linkend="story">six
  typical users</link>, whose testing needs &qmtest; is designed to
  address. It then explores their <link
  linkend="req">requirements</link> in more detail, in order to
  determine the features that &qmtest; must have. &qmtest;'s <link
  linkend="arch">architecture</link> and <link linkend="iface">user
  interface</link> are described next, along with some details of its
  <link linkend="impl">implementation</link>. These are followed by a
  provisional <link linkend="devplan">development plan</link> and an
  analysis of the <link linkend="risk">risks</link> the project
  faces. </para>

  <section><title>What &qmtest; is Not</title>

   <para>In order to bound the scope of this project, it is important
   to understand that:</para>

   <para>
    <itemizedlist>
     <listitem>
      <para>&qmtest; is not a build system. It will not determine which
      parts of the programs being tested need to be recompiled, or
      which test programs need to be re-linked. It
      <emphasis>may</emphasis> include support for re-running tests
      whose last recorded result is older than the thing being
      tested.</para>
     </listitem>

     <listitem>
      <para>&qmtest; is not a version control system, or a relational
      database. In particular, versioning of tests will be handled by
      whatever version control system developers are already
      using. Similarly, &qmtest; will log the results of tests, but will
      rely on the capabilities of external systems to maintain
      historical records. Note, however, that &qmtest;
      <emphasis>will</emphasis> be able to retrieve information from
      those archiving systems in order to create
      reports.</para>
     </listitem>

     <listitem>
      <para>&qmtest; is not a test creation wizard, although
      tools for creating &qmtest;-compatible tests will be developed with
      it.</para>
     </listitem>

     <listitem>
      <para>&qmtest; is not a general program execution harness. Some
      users may choose to run their programs via &qmtest; under non-test
      circumstances (e.g. in order to obtain logging information), but
      &qmtest; is not a replacement for distributed load-balancing
      software, safe shells, or other tools.</para>
     </listitem>
    </itemizedlist>
   </para>

  </section>

  <section><title>Acknowledgements</title>

   <para>This document has its origins in the submissions to the
   testing category of the Software Carpentry design competition in
   the spring of 2000, and in the hundreds of messages on the Software
   Carpentry discussion list in August--October of the same year.  We
   are grateful to Paul Dubois (<ulink
   url="http://www.llnl.gov">Lawrence Livermore National
   Laboratory</ulink>), Stephen Lee (<ulink
   url="http://www.lanl.gov">Los Alamos National Laboratory</ulink>),
   Brian Marick (of <ulink
   url="http://www.testing.com">testing.com</ulink>), Ken Martin
   (<ulink url="http://www.kitware.com">Kitware</ulink>), and Dave
   Thomas (a very <ulink
   url="http://www.pragmaticprogrammer.com">pragmatic
   programmer</ulink>) for their input.</para>

  </section>

  <section><title>User Profiles</title>

   <section><title>Bhargan Basepair</title>

    <para>Bhargan Basepair develops fuzzy DNA pattern-matching
    algorithms for a bio-technology firm called Genes'R'Us.  As a
    semi-official service for his colleagues, he runs an overnight DNA
    sequence query service.  Researchers email DNA sequences to him;
    Bhargan saves these messages in files called
    <filename>search/a</filename>, <filename>search/b</filename>, and
    so on, then edits them to add query directives. </para>

    <para>Before going home at night, he runs a Unix shell script
    which searches the database for each sequence in the
    <filename>search</filename> directory.  The results are put in
    files called <filename>search/a.out</filename>,
    <filename>search/b.out</filename>, and so on.  Each search
    typically takes 15-20 minutes; he is sometimes not able to run all
    of the searches he has received in a single night.  When Bhargan
    comes in the next morning, he mails out the
    <filename>.out</filename> files, then examines the search logs to
    see if he can improve the performance of his search
    engine. </para>

    <para>Bhargan has written a small Python program to automate this
    process, and now wants to test it.  His main concerns are:
     <itemizedlist>
      <listitem>
       <para>One person's results must <emphasis>never</emphasis> be
       sent to someone else -- there could be legal fallout if this
       ever happened.</para>
      </listitem>

      <listitem>
       <para>Queries should never be lost or garbled: anyone who sends
       a valid query should eventually get a reply.</para>
      </listitem>

      <listitem>
       <para>The system should only run the search if the user has
       specified sensible parameters (so that researchers don't get
       results for a search other than the one they thought they were
       running). </para>
      </listitem>

      <listitem>
        <para>The test program shouldn't send mail to real people, or
        be sent mail from them.  The corporate IT department might be
        willing to set up dummy user accounts for Bhargan to use in
        testing, but he'll probably see the millenium roll over again
        before it actually gets done.</para>
      </listitem>

     </itemizedlist>
    </para>

   </section>

   <section id="story-diana">
    <title id="story-diana-title">Diana Dowhile</title>

    <para>Diana studied parsing algorithms for her Master's degree in
    Computer Science at Euphoric State University.  She is now
    implementing a Fortran-2000 (or "F00") parser for the GNU Compiler
    Collection (GCC).  The parser currently contains 47,000 executable
    lines of C and C++ in 350 functions, distributed among 18 files,
    and is expected to triple in size by the time the project is
    done.</para>

    <para>Diana starts work on each language feature by writing a few
    new test cases that exercise it.  (Many of these tests are
    actually not legal F00, since one of her goals is to improve the
    compiler's error messages.) Diana only starts implementing the
    feature itself once all of his test cases are written and
    failing&mdash;past experience has taught her that if she writes
    her tests <emphasis>after</emphasis> implementing the feature, she
    will test against her implementation, and not against the language
    standard.</para>

    <para>Diana has inherited a collection of approximately 1200
    tests, most written to test GCC's existing Fortran-77 parser.
    These test files are scattered throughout the GCC source tree.
    Each test consists of one or more specially-formatted comments
    embedded in a Fortran source file.  A simple shell script extracts
    these comments, runs the F00 parser with the parameters contained
    in the comment, and compares the output with the expected output
    (which is also embedded in the comment). The test is considered a
    pass if the compiler emits exactly the output expected.</para>

    <para>Diana would like a tool to re-run his tests automatically,
    and to collect statistics on how many tests have been executed,
    with what results.  She would also like some help generating
    tests: many are simple variations on a theme, such as using
    eighteen different kinds of constants as array subscripts, and she
    has made several errors in the tests themselves when copying and
    modifying old test files.  Finally, she would like a single
    command to run the entire test suite simultaneously on each of the
    dozen or so different machines in the testing network.  These
    machines are a mix of various versions of Unix and Microsoft
    Windows.</para>

   </section>

   <section id="story-ovide">
    <title>Ovide Overlay</title>

    <para>Ovide Overlay is developing new map overlay algorithms for a
    geographical information system.  The system takes two maps A and
    B as input.  Each map covers the same geographical area, and is
    divided into non-overlapping polygons.  The module's output is the
    the map that would be generated by drawing the input maps on
    transparent film, and placing them on top of each other.  For
    example, if A shows soil types, and B shows vegetation, the map
    shows where different kinds of plants are growing on different
    types of soil.</para>

    <para>In order to simplify his studies, Ovide is using maps
    divided into rectangles, whose vertices all lie on a
    [0...X]&times;[0...Y] grid.  His reference program implements a
    naive "all-against-all" overlay algorithm, in which every
    rectangle in map A is tested against every rectangle in map B.
    Ovide wants to implement and test several refinements of this
    algorithm.  His most important testing requirement is to make sure
    that the new algorithms generate the same results as the old ones,
    i.e. that his performance optimizations do not introduce bugs.
    His second requirement is that his test suite record and report
    the performance of the new algorithms on some of the test data
    sets&mdash;he wants to avoid the redundant work involved in
    building one re-execution environment for testing, and another for
    performance measurement.
    </para>

   </section>

  </section>

 </chapter>

 &req.xml;
 &core.xml;
 &arch.xml;
 &impl.xml;
 &refs.xml;

</book>

<!--
  Local Variables:
  mode: sgml
  indent-tabs-mode: nil
  sgml-indent-step: 1
  sgml-always-quote-attributes: t
  sgml-general-insert-case: lower
  sgml-minimize-attributes: nil
  End:
-->
