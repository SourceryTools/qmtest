<?xml version="1.0"?>
<!--

  File:   core.xml
  Author: Mark Mitchell, Alex Samuel, Greg Wilson
  Date:   2000-11-01

  Contents:
    Core architecture of qmtest.

  Copyright (C) 2000 CodeSourcery LLC.  This material may
  be distributed only subject to the terms and conditions set forth in
  the Open Publication License (see the file LICENSE.OPL).

-->
<chapter id="chap-requirements">
 <title>Requirements</title>

 <para>This section lists requirements derived from the use cases
 presented above, and from the discussions on the Software Carpentry
 mailing list.  The four most important requirements (<link
 linkend="sec-req-accuracy">accuracy</link>, <link
 linkend="sec-req-smallscale">usability</link>, <link
 linkend="sec-req-reproducible">reproducibility</link>, and <link
 linkend="sec-req-standards">conservatism</link>) are
 presented first; secondary or derived requirements follow.</para>

 <section id="sec-req-accuracy">
  <title id="sec-req-accuracy-title">Accuracy</title>

  <para>The most important requirement for &qmtest; is accuracy: it
  must never report that a test has succeeded when in fact it has
  failed, or vice versa. (In statistical terminology, there must be
  <phrase id="discuss-false-positives">no false positives</phrase> and
  <phrase id="discuss-false-negatives">no false negatives</phrase>.)  A
  corollary of this requirement is that &qmtest; must <phrase
  id="discuss-execute-all">always execute at least all of the tests
  requested by the user</phrase>.  Ideally, it should only execute
  exactly these tests, but in practice, it is acceptable for &qmtest;
  to run more tests than the user asked for, so long as all of the
  tests that were asked for are run.</para>

 </section>

 <section id="sec-req-smallscale">
  <title id="sec-req-smallscale-title">Small-Scale Usability</title>

  <para><phrase id="discuss-small-use">Small-scale testing must be
  easier to do with &qmtest; than by hand</phrase>.  If &qmtest;
  requires users to do things that only pay off on medium or large
  projects, many of those users will choose to do ad hoc testing
  initially, instead of using &qmtest;.  In theory, users could then
  switch to &qmtest; when its adoption cost was outweighed by its
  benefits, but in practice, those ad hoc test suites will usually
  grow (or, more likely, rust) as their projects grow.</para>

 </section>

 <section id="sec-req-reproducible">
  <title id="sec-req-reproducible-title">Reproducibility</title>

  <para><phrase id="discuss-reproducible">Test execution must be
  reproducible</phrase>: &qmtest; must be able to recreate the
  starting point for a particular run of a test exactly.  This
  requirement is necessary in order to minimize the burden on human
  users: without it, it could be necessary to repeatedly re-run a test
  that reported an error or failure in order to isolate the fault.
  Note that this does not mean that the test result is exactly
  reproducible&mdash;some tests of network software and user
  interfaces are intrinsically non-deterministic&mdash;but all
  controllable variables (such as random number generator seeds) must
  be stored in a re-executable way.</para>

 </section>

 <section id="sec-req-standards">
  <title id="sec-req-standards-title">Conservatism</title>

  <para>&qmtest; <phrase id="discuss-recycle">must use existing
  standards, syntax, conventions, and tools</phrase> wherever
  possible.  In this way, it will be easier for users to adopt
  &qmtest;, easier for developers to build and modify &qmtest;, and
  easier for other tools to integrate with &qmtest;, and easier to
  take advantages of improvements to other components used in
  &qmtest;.</para>

  <para>The specific implications of this requirement are:
   <itemizedlist>
    <listitem>
     <para>Where &qmtest; needs structured data storage, the format of
     that storage will be defined in terms of &xml;.  This does
     <emphasis>not</emphasis> mean that only &xml; will be used: flat
     text, executable scripts, relational database schemas, persisted
     Python scripts, and other formats may be supported as well.
     However, since &xml; is more constraining than these formats,
     designing in terms of it will ensure that all features are
     available in all modes.  </para>
    </listitem>

    <listitem>
     <para>Where &qmtest; needs to expose quoting rules,
     floating-point numbers, or other programmatic constructs to
     users, it will use the syntax defined for Python.  Note that this
     does <emphasis>not</emphasis> mean that &qmtest; will be
     Python-centric; the rationale is simply that there is no point
     defining yet another set of rules for writing things like:
      <programlisting>
       output &lt; 5.0 and command != "start\n"
      </programlisting>
     </para>
    </listitem>

    <listitem>
     <para>Where &qmtest; needs data formats (e.g. parameters for
     procedure calls), it will use the rules included in the draft
     SOAP standard.  Again, this does <emphasis>not</emphasis> mean
     that only SOAP will be used in the system; as with programmatic
     syntax, however, there seems to be little point developing yet
     another set of rules for describing or constraining such things
     as arrays of strings.</para>
    </listitem>
   </itemizedlist>
  </para>

  <para>A "negative" standards requirement is that &qmtest; <phrase
  id="discuss-not-all-cmdline">must not require all tests to be
  command-line applications</phrase>.  In particular, tests
  <emphasis>may</emphasis> have access to standard input and standard
  output, and <emphasis>may</emphasis> be able to report success or
  failure by exiting with a zero or non-zero status, but &qmtest; does
  not insist upon this.  This requirement is necessary because many
  applications of interest may be long-lived services (e.g. a web
  server), or may rely on a framework (such as the Microsoft
  Foundation Classes or some Java <acronym>gui</acronym> frameworks)
  that does not provide standard input or standard output.</para>

 </section>

 <section id="sec-req-dependent-tests">
  <title>Dependent and Independent Tests</title>

  <para>&qmtest; must <phrase id="discuss-specify-dependency">allow
  programmers to specify dependencies among tests</phrase>, and must
  <phrase id="discuss-track-dependency">prevent dependent tests from
  being executed if an error occurred in an antecedent</phrase>.  For
  obvious reasons, dependencies among tests must be acyclic;
  &qmtest; must <phrase id="discuss-cyclic-dependency">detect and
  report cyclic dependencies</phrase>.  &qmtest; should try to detect
  and report cyclic dependencies before executing any tests, but is
  not required to do this, since this may not be possible if tests are
  being <link linkend="sec-req-multi">generated on the fly</link>.</para>

  <para>Finally, it must be possible to <phrase
  id="discuss-separate-prep">separate setup and cleanup from
  particular tests</phrase>, so that the modified environments
  required for dependent tests are not destroyed before those tests
  are executed.  &qmtest; must <phrase
  id="discuss-trace-dependency">trace dependencies among
  tests</phrase>, and automatically determine when to set up and clean
  up.  If possible, &qmtest; should share dependency
  detection and management functionality with &qmbuild;.</para>

  <para>One scenario in which significant setup or cleanup actions are
  required is database testing.  The test system should be able to
  populate an empty database with several million records, perform
  tests that query the database, and then remove the database from the
  user's system.  It would be woefully inefficient to re-populate the
  database for each test, so the setup and cleanup actions must be
  able to span multiple tests.</para>

 </section>

 <section id="sec-req-expected">
  <title>Expected and Unexpected Results</title>

  <para>There are often periods in a development cycle during which
  certain tests are expected to fail.  For example, if Extreme
  Programming's "test, then code" development model is being used, all
  of a module's tests will initially fail.  &qmtest; must therefore
  allow programmers to <phrase id="discuss-expect-failure">specify
  that some tests are expected to fail</phrase>.  It must also <phrase
  id="discuss-reported-expected-failures">report expected failures
  separately from passes, unexpected failures, and other
  results</phrase>.</para>

  <para>In many cases, tests will fail under some configurations and
  not others.  For example, a compiler might generate correct code for
  a PowerPC but incorrect code for a SPARC.  Similarly, a scientific
  application might perform correctly when using a conventional matrix
  representation, but incorrectly when using an optimized
  representation.  Therefore users must be able to indicate that
  certain tests are expected to fail only in certain
  circumstances.</para>

 </section>

 <section id="sec-req-reporting">
  <title>Reporting</title>

  <para>&qmtest; must be able to <phrase
  id="discuss-readable-report">report test results in textual,
  human-readable form</phrase>.  This is necessary for two reasons:
   <orderedlist>
    <listitem>
     <para>While all version control systems are able to find and
     display micro-differences between text files, most are not able
     to do this for binary files.  Since users may archive test
     results along with the tests themselves (and the code being
     tested), &qmtest; must be designed to facilitate this.
     </para>
    </listitem> 

    <listitem>
     <para>Many developers still use command-line tools, and will want
     to run &qmtest; from the command line.  Its output must therefore
     be viewable without external helper applications, such as web
     browsers.  </para>
    </listitem>
   </orderedlist>
  </para>

  <para>This requirement does <emphasis>not</emphasis> imply that flat
  text will be &qmtest;'s only, or usual, output format.  In
  particular, &xml;-aware tools are maturing and becoming common.
  &qmtest; must therefore be able to <phrase
  id="discuss-report-xml">report and store test results as
  &xml;</phrase>.  This will make it easier for &xml;-aware integrated
  development environments (<acronym>IDE</acronym>s) and version
  control systems to leverage the semantic content of &qmtest;'s
  output.</para>

  <para>Requiring test authors to write tests that can generate output
  in two or more formats is an unacceptable burden.  &qmtest; must
  therefore <phrase id="discuss-format-function">provide test result
  formatting and reporting functions in all programming languages of
  interest</phrase>.  The <phrase id="discuss-format-switch">format in
  which these functions report results must be controlled by a single
  switch</phrase>, i.e. there cannot be separate functions for
  different reporting formats. </para>

 </section>

 <section id="sec-req-reference"><title>Regeneration of Reference Results</title>

  <para>Users are often interested in checking whether or not a
  particular change to a program causes new failures.  Therefore,
  &qmtest; must be able to determine automatically the expected
  outcome of a test by comparing it to a known set of outcomes.  In
  this way, users can discern the difference between the situation in
  which a test is failing <emphasis>independently</emphasis> of a
  source-code change, and the situation in which a test is failing
  <emphasis>due</emphasis> to a source code change.</para>

  <para>For example, &qmtest; might be run nightly to generate
  reference results.  Then, even if an erroneous change was checked in
  the previous day, developers would realize that their current
  changes were not responsible.  Of course, &qmtest; would also
  generate a report indicating that the reference results had
  regressed from one night to the next.</para>

 </section>

 <section id="sec-req-suites"><title>Test Suites</title>

  <para>&qmtest; must allow test authors to <phrase
  id="discuss-test-suites">aggregate tests into test suites</phrase>
  so that large collections of tests can be run at once.  It is
  natural to allow test suites to contain other test suites.  For
  example, this facilitates building a test suite for an entire
  program out of the test suites for each component of the
  program.</para>

  <para>Although test suites may contain other test suites, test
  suites do not in general form a tree.  For example, an organization
  might wish to execute a few representative tests from the component
  test suites each time a change was made to any part of the product.
  Thus, a single test can be in more than one test suite.</para>

  <para>Because test suites are collections of tests, there is no
  sense in which a suite "passes" or "fails".  There is no unique way
  in which to classify an arbitrary combination of pass, fail, and
  error outcomes into a single result.  However, as discussed below
  users can use <link linkend="sec-req-summary-reporting">summary
  reports</link> to obtain information about the number of tests which
  passed or failed within a particular suite.</para>

 </section>

 <section id="sec-req-test-identification">
  <title>Test Identification</title>
 
  <para>&qmtest; must support the use of human-readable and memorable
  test names so that users can easily recognize failing tests and
  communicate with each other about the tests.  Test names should be
  hierarchical to facilitate easy organization and easy storage of
  tests in the file system.  These identifiers must be persistent; the
  name of a test must not change as tests are added or removed from the
  test database.</para>

 </section>

 <section id="sec-req-summary-reporting">
  <title id="sec-req-summary-reporting-title">Summary Reporting</title>

  <para>&qmtest; must <phrase id="discuss-summarize-results">summarize
  the outcomes (passes or failures) of the tests executed</phrase> by
  producing a count of the number of tests for which each outcome
  occurred.  This <phrase
  id="discuss-hierarchical-reporting">reporting must be
  hierarchical</phrase>: users must be able to inspect the summaries
  for suites, the test suites within those suites, and so on.  Finally,
  <phrase id="discuss-report-record">reporting and recording must be
  independent</phrase>, i.e. &qmtest; must be able to record more
  information about test results than it provides in summary reports,
  so that users can analyze failures in more detail.</para>

 </section>

 <section id="sec-req-info">
  <title id="sec-req-info-title">Extra Information</title>

  <para>In many cases, it is useful to include more information than
  simply the outcome (pass or fail) of the test.  For example, it may
  be desirable to have tests report execution time, memory usage,
  number of context switches, or code coverage.  &qmtest; <phrase
  id="discuss-extra-values">must allow tests to contain and report
  extra named values</phrase>, while the <phrase
  id="discuss-summarize-extra-values">summary reporting system must
  allow extra named values to be combined
  hierarchically</phrase>.</para>

  <para>One common case in which extra information is provided is to
  <phrase id="discuss-explain-deferral">explain why specific tests
  were untested</phrase>.  If a test cannot be executed except when
  certain conditions hold, then the factors that caused the test not
  to be executed should be included in the result.</para>

 </section>

 <section id="sec-req-traversal">
  <title id="sec-req-traversal-title">Selective Execution</title>

  <para>&qmtest; must of course be able to <phrase
  id="discuss-automatic-traversal">automatically execute all the tests
  in a test suite.</phrase>  However, it must also be possible for users to
  explicitly <phrase id="discuss-user-control-traversal">specify the
  tests or suites to be executed</phrase>, either positively, by
  indicating the tests which should be run, or negatively, by
  indicating the tests which should not be run.  Summary reports for
  runs using selective execution should explicitly note those tests
  that were explicitly included or omitted.</para>
 
  <para>&qmtest; must be able to <phrase
  id="discuss-filter-by-result">re-execute automatically only those
  tests that produced specific outcomes during a previous
  run</phrase>.  In this way, users can attempt to fix new failures,
  and automatically retest just the new failures.</para>

  <para>&qmtest; must be able to execute selectively only those tests
  that meet certain selection criteria, such as those tests that
  should be executed on a particular hardware platform, or those tests
  that test certain software components.</para>

 </section>

 <section id="sec-req-test-suite-organization">
  <title>Test suite Organization</title>

  <para>&qmtest; <phrase id="discuss-physical-structure">must not
  dictate the locations of tests (or associated data) in the file
  system.</phrase> Users require the ability to place tests in a
  variety of locations, partly so that they can use their usual source
  control systems with the tests.  &qmtest; must therefore allow users
  to <phrase id="discuss-specify-locations">separately specify the
  location of tests, temporary files, and results</phrase>.  In order
  to avoid placing too great a burden on first-time users, however,
  &qmtest; <phrase id="discuss-default-locations">must not require
  explicit specification of object locations</phrase>. If the user
  does not explicitly specify particular locations for these various
  entities, the &qmtest; must provide sensible defaults.</para>

  <para>&qmtest; <phrase id="discuss-no-redundancy">must not require
  redundant specification</phrase> of test location.  For example, the
  user should be able to specify once, at the root of the testing
  hierarchy, that intermediate files are to be put in
  <filename>/tmp</filename>, and that test results are to be archived
  in the same directories as tests themselves.  The tests and
  test suites included within this hierarchy should automatically
  inherit this behavior.</para>

 </section>

 <section id="sec-req-controlling-execution">
  <title>Controlling Execution</title>

  <para>The longer a test suite takes to run, the less frequently it
  will be used.  &qmtest; therefore <phrase id="discuss-parallel">must
  be able to execute tests concurrently</phrase> when the resources
  needed to do so are available.  In order to encourage test
  developers to structure tests so that they do not contain
  dependencies that would inhibit concurrent execution, <phrase
  id="discuss-out-of-order">unordered execution will be the
  default</phrase>, although <phrase id="discuss-in-order">specifying
  test order must be supported as well</phrase>.</para>

  <para>&qmtest; must also allow users to <phrase id="discuss-timeout"
  >specify timeouts and resource limits when executing tests or
  test suites</phrase>.  These limits must override any that are built
  into the test specification. </para>

 </section>

 <section id="sec-req-spec">
  <title>Test Specification</title>

  <para>&qmtest; must be able to test programs using a variety of
  methods, including:</para>

  <glosslist>

   <glossentry>
    <glossterm id="discuss-standalone-call">Parsing the output from a
    program</glossterm>
    <glossdef>
     <para>The test developer writes a program that contains a single
     call to a single test subject.  When the program is executed, the
     test framework inspects the result of the call to the test
     subject (which may mean trapping errors), compares this to the
     result the developer expected, and produces a textual report in a
     standard format, from which &qmtest; can extract the test result.
     Note that this case includes the case in which the "call" is
     actually a series of calls, at the end of which a single test
     result is generated.</para>
    </glossdef>
   </glossentry>

   <glossentry>
    <glossterm id="discuss-translate-call">Report translation from
    a single stand-alone executable</glossterm>
    <glossdef>
     <para>The test developer specifies a program to be executed.
     This may be a special-purpose testing program, or it may be the
     test subject itself.  The program does not produce a test result
     directly.  Instead, the test specification describes how to
     translate one or more observable aspects of the program's
     behavior into a test result.  Some common cases include:
      <itemizedlist>
       <listitem>
        <para><phrase id="discuss-translate-exit-code">Translate a
        program's exit status code into a test result</phrase>,
        automatically trapping unexpected abnormal ends such as
        floating point exceptions or memory access violations.</para>
       </listitem>

       <listitem>
        <para><phrase id="discuss-translate-file-diff">Compare the
        program's output to a reference copy.</phrase> This <phrase
        id="discuss-translate-custom-diff">must be able to use an
        user-specified comparator to determine whether a program's
        output matches a reference result</phrase>.</para>
       </listitem>

       <listitem>
        <para><phrase id="discuss-translate-side-effect">Inspect one
        or more of the side effects of the program's
        execution</phrase> (such as output files or changes to
        directory or file permissions) and produce a test
        report. </para>
       </listitem>

       <listitem>
        <para>Run the test subject and <phrase
        id="discuss-translate-monitor">construct a report based on the
        output of a monitoring program</phrase>, such as a memory
        usage checker.</para>
       </listitem>
      </itemizedlist>
     </para>
    </glossdef>
   </glossentry>

   <glossentry>
    <glossterm id="discuss-multiple-calls">Multiple reports from a
    single executable</glossterm> 
    <glossdef>
     <para>The test developer writes a program that contains multiple
     calls to multiple test subjects.  Each call results in a single
     test report, so that when the test program is run, many test
     reports are produced.</para>
    </glossdef>
   </glossentry>

   <glossentry>
    <glossterm>Multiple runs of a single subject with different
    options</glossterm>
    <glossdef>
     <para>All of the cases above (and below) may be repeated many
     times with different options, such as different command-line
     arguments, input files, configuration files, thresholds, and so
     on.  &qmtest;'s users therefore <phrase
     id="discuss-arg-calls">must be able to specify
     repetition</phrase> in a simple way.</para>
    </glossdef>
   </glossentry>

   <glossentry>
    <glossterm id="discuss-direct-calls">Direct calls to the test
    subject</glossterm>
    <glossdef>
     <para>In some cases, it may be necessary or desirable to have
     &qmtest; itself call the test subject.  In particular, the test
     subject may be a <acronym>COM</acronym> or
     <acronym>CORBA</acronym> component, a JavaBean, or a function or
     procedure in a dynamic language such as Perl, Python, or Ruby.
     In these cases, the test developer must be able to test the code
     without starting a separate process.</para>
    </glossdef>
   </glossentry>
  </glosslist>

  <para>As well as reading test specifications from standard &qmtest;
  specification files, &qmtest; must be able to extract test
  specifications from arbitrary legacy test descriptions, using
  special filters.  For example, if Diana Dowhile already has 1200
  test specifications embedded as specially-formatted comments in
  program source files; &qmtest; must allow her to recycle those
  files.</para>

 </section>

 <section id="sec-req-multi">
  <title>Programmatically Generated Tests</title>

  <para>Users will often want to generate multiple tests
  programmatically in cases where generating tests manually is
  impractical.  For example, <link linkend="story-ovide">Ovide</link>
  may write a small program that generates all 169 different possible
  cases of two rectangles overlapping (or failing to overlap).
  &qmtest;'s Python-based design specifically accommodates this
  requirement by providing interfaces by which users can produce
  custom test suites that generate tests on the fly.</para>

 </section>

 <section id="sec-req-updown">
  <title id="sec-req-updown-title">Setup and Cleanup</title>

  <para>Individual tests and test suites may require arbitrary setup
  before, and cleanup after, their execution.  In order to simplify
  test management, &qmtest; requires that <phrase
  id="discuss-prep-in-spec">setup and cleanup must be specified in
  the test specification</phrase>, that <phrase
  id="discuss-log-prep">setup and cleanup operations must be
  logged</phrase> when tests are executed, and that <phrase
  id="discuss-test-after-setup">tests are only executed if their setup
  operations complete successfully</phrase>.  Users are encouraged to
  specify cleanup operations so that they will execute correctly
  (i.e. return the environment to its pre-test state) even if setup
  and the test itself failed partially or completely.</para>

  <para>In order to avoid drowning users in detail, &qmtest; must log
  setup failure as a reason not to execute a test, but <phrase
  id="discuss-first-error">should only report significant setup errors
  by default</phrase>.  For example, if test B depends on test A, and
  test A's setup fails, &qmtest; should not report that test B has
  failed, since the root cause is the failure in test A's
  setup.</para>

 </section>

 <section id="sec-req-sandbox">
  <title id="sec-req-sandbox-title">Sandboxing and Throttling</title>

  <para>A <firstterm>sandbox</firstterm> is an environment for program
  execution in which some or all of the facilities the program relies
  on have been replaced with safer, or simpler, versions.  For
  example, a developer could construct a sandbox for a mailing list
  manager by replacing the SMTP library with one which wrote messages
  to a log file, and read messages from a specially-formatted input
  file, rather than interacting with the outside world.</para>

  <para>A <firstterm>throttle</firstterm> is anything used to restrict
  a program's execution environment, e.g. a very small heap, or a
  small upper bound on the number of threads a process is allowed to
  spawn.  Throttles are typically used to simulate the effects of
  heavy system loads: running a program with a small heap, for
  example, is a good way to test how it will behave when it needs to
  allocate many large data structures.</para>

  <para>While future versions of &qmtest; may come packaged with
  sandbox and throttle libraries for specific languages and
  applications, these are out of the scope of the current effort.
  However, in order to make it easy for developers to use these
  facilities today (if they have them), &qmtest; <phrase
  id="discuss-record-build-options">must be able to record the build
  options of all tests</phrase>, including compiler options, linked
  libraries, and so on.</para>

 </section>

</chapter>

<!--
  Local Variables:
  mode: sgml
  indent-tabs-mode: nil
  sgml-indent-step: 1 
  sgml-always-quote-attributes: t
  sgml-general-insert-case: lower
  sgml-minimize-attributes: nil
  sgml-parent-document: ("qmtest.xml" "book" "chapter")
  End:
-->
