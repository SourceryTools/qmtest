<?xml version="1.0"?>
<!--

  File:   test-tour.xml
  Author: Alex Samuel
  Date:   2000-11-01

  Contents:
    Grand tour/tutorial of QMTest.

  Copyright (C) 2001 CodeSourcery LLC.  This material may
  be distributed only subject to the terms and conditions set forth in
  the Software Carpentry Open Publication License, which is available at:

    http://www.software-carpentry.com/openpub-license.html

-->
<chapter id="chap-test-tour">
 <title>Getting Started with &qmtest;</title>
 
  <para>The &qm; distribution includes an example test database.  This
  tutorial shows you how to perform basic &qmtest; operations, using the
  example test database.</para>

  <para>Some of the examples use Python-based tests, but you don't
  really need to know Python to understand them.  You will have to know
  some Python to understand <xref linkend="sec-testtut-test-class"/>,
  though.</para>

  <section id="sec-testtut-setting-up">
   <title>Setting Up</title>

   <para>To use &qmtest;, you'll need a <link
   linkend="sec-test-database">test database</link>. The test database
   is a directory in which &qmtest; stores information about tests and
   other objects.  The test database contains XML files, Python files,
   and subdirectories, but for simple operations there's no need to look
   inside the database directly.</para>

   <para>If you wish to create a new, empty test database from scratch,
   simply create an empty directory.  However, for this tutorial, we'll
   use the example test database provided with &qmtest;, which includes
   some demo tests.  Since we'll modify the test database later in the
   tutorial, start by making a copy of it.  Copy the entire test
   database directory tree to another location.  On a UNIX-like system,
   you could make a copy named <filename>tdb</filename> in your home
   directory by invoking this command:</para>

   <screen>
    &prompt;<userinput>cp -r /usr/local/share/qm/tutorial/test/tdb ~/tdb</userinput>
   </screen>

  </section> <!-- sec-testtut-setting-up -->

  <section id="sec-testtut-running-tests">
   <title>Running Tests</title>

   <para>You can access all &qmtest; functions via the &qmtest-cmd;
   program.  When you invoke &qmtest-cmd;, you must specify a command
   argument, which tells the program which action to perform.  Some
   commands require additional arguments, which you should place after
   the command.  Also, you may specify general options to &qmtest-cmd;
   (with flags that come before the command), and options to individual
   commands (with flags that come after the command).</para>

   <para>To see a list of available commands, and general options to
   &qmtest-cmd;, invoke it with the <option>&dashdash;help</option> (or
   <option>-h</option>) option.  To see a description of each command,
   and additional options specific to that command, invoke
   <command>qmtest <replaceable>command</replaceable>
   &dashdash;help</command>.</para>

   <para>You must tell &qmtest; which test database to use by specifying
   the <option>&dashdash;test-db</option> (or <option>-D</option>)
   option and providing the path to the test database.  Alternately, you
   can save typing by defining the environment variable
   <envar>QMTEST_DB_PATH</envar> to specify the test database
   path.</para>

   <para>The command for running tests is <command>&qmtest-cmd;
   run</command>.  You may specify one or more IDs of tests and test
   suites to run.  To run all tests in the test database, omit these IDs
   from the command line.</para>

   <para>Assuming you made a copy of the example test database as
   described in the previous section, try this command, to run all the
   tests in the database:</para>

   <screen>
&prompt;<userinput>qmtest -D ~/tdb run</userinput>
   </screen>

   <para>Equivalently, you could set <envar>QMTEST_DB_PATH</envar>, and
   omit the <option>-D</option> option.  Subsequently in this tutorial,
   we'll assume you've set this environment variable.  If you're using a
   Bourne-style shell, you might invoke these commands instead:</para>

   <screen>
&prompt<userinput>export QMTEST_DB_PATH=~/tdb</userinput>
&prompt<userinput>qmtest run</userinput>
   </screen>

   <para>&qmtest; runs the tests, and prints a summary of the test
   run:</para>

   <screen><computeroutput><![CDATA[
--- TEST RUN STATISTICS ------------------------------------------------------

       3        tests total

       2 ( 67%) tests PASS
       1 ( 33%) tests FAIL


--- TESTS THAT DID NOT PASS --------------------------------------------------

  exec1                                                          : FAIL    
      Expression evaluates to false.


]]></computeroutput></screen>

   <para>&qmtest; prints out two things.  First, it displays statistics
   about the tests that were run.  Three tests were actually run.  These
   are broken down by <link linkend="sec-outcomes">test outcome</link>:
   two of them passed, and one failed.  Following the statistics
   summary, &qmtest; lists the IDs of all tests whose outcome was not
   passing, in this case the single test <literal>exec1</literal>.
   After the designation &FAIL; is a brief description of why the test
   failed.</para>
   
  </section> <!-- sec-testtut-running-tests -->

  <section id="sec-testtut-results">
   <title>Test Results</title>

   <para>Why did test <literal>exec1</literal> fail?</para>

   <para>&qmtest; can generate comprehensive results for a test run.
   Test run results are formatted as an XML document, and may include
   additional information about each test's execution, depending on the
   test.  To generate XML test results, use the
   <option>&dashdash;output</option> (or <option>-o</option>) option,
   and specify a file name for the resulting file.</para>

   <para>To learn more about the failed test <literal>exec1</literal>,
   let's run it again, this time instructing &qmtest; to write results
   to the file <filename>results.xml</filename>.  Note that since we're
   specifying a single test, &qmtest; doesn't run all the tests in the
   test database.</para>

   <screen>
&prompt;<userinput>qmtest run -o results.xml exec1</userinput>
   </screen>

   <para>&qmtest; generates this output in
   <filename>results.xml</filename>:</para>

   <programlisting><![CDATA[<?xml version='1.0' encoding='ISO-8859-1'?>
<!DOCTYPE test-run PUBLIC "-//Software Carpentry//QMTest Result V0.2//EN" "http://www.software-carpentry.com/qm/xml/result.dtd">
<test-run>
 <test-results>
  <result id='exec1'>
   <outcome>FAIL</outcome>
   <property name='value'>0</property>
   <property name='target'>local</property>
   <property name='cause'>Expression evaluates to false.</property>
  </result>
 </test-results>
 <resource-results/>
</test-run>
]]></programlisting>

   <para>Notice the single <sgmltag class="element">result</sgmltag>
   element, whose <sgmltag class="attribute">id</sgmltag> attribute is
   the test ID <literal>exec1</literal>.  For this test, the result
   contain the outcome &FAIL;, indicating a failing test; the cause,
   which was displayed in square brackets in the test summary; and an
   additional property "value."  To understand this property, we have to
   know more about <literal>exec1</literal> and its test class.  A test
   class is a template that describes how to run a test and generate
   test results.  In brief, the test class for <literal>exec1</literal>
   defines a test as passing if a Python expression given in the test
   evaluates to true (i.e. evaluates to a value that is considered to
   have a boolean true value in Python).  The expression for test
   <literal>exec1</literal> evaluated to zero, which has a false value
   in Python, so the test failed.</para>

  </section> <!-- sec-testtut-results -->

  <section id="sec-testtut-examining">
   <title>Examining Tests</title>

   <para>Now let's look at the tests in the test database.  &qmtest;
   provides a web-based graphical user interface for browsing and
   editing tests, resources, and test suites.</para>

   <para>The <command>qmtest server</command> command starts a miniature
   web server, which generates the user interface.  Once you've started
   the web server, you can point your web browser at it to access the
   user interface, or you can have &qmtest; start a web browser for you
   automatically.  You may specify a port number on which to run the web
   browser using the <option>&dashdash;port</option> (or
   <option>-P</option>) option; if you omit this, &qmtest; will use
   port 8000.  The <option>&dashdash;start-browser</option> (or
   <option>-b</option>) instructs &qmtest; to attempt to open a web
   browser and point it at the running server.</para>

   <para>Try starting the web user interface with this command:</para>

   <screen>
&prompt;<userinput>qmtest server -b</userinput>
   </screen>

   <para>If all goes well, &qmtest; starts the server and then points
   your web browser at it.  On some systems, &qmtest; may be unable to
   start a web browser automatically.  In this case, you can configure
   &qmtest; to find your browser (see <xref linkend="sec-rc-common"/>).
   Or, you can start the server separately by omitting the
   <option>-b</option> option; &qmtest; will print out the appropriate
   URL, and you can copy it into your web browser manually.</para>

   <para>The page you should see in your browser lists the contents of
   the test database (three tests), plus buttons for adding new tests,
   resources, and suites.  The <guilabel>Full Listing</guilabel> link in
   the upper-right corner will return you to this page.</para>

   <para>Each test ID is a hyperlink.  Clicking on it will take you to a
   page displaying that test.  Click on the link for test
   <literal>exec1</literal>, the one that is failing.</para>

   <para>&qmtest; now shows you full details about test
   <literal>exec1</literal>.  Towards the top, in grey, is information
   about this test's test class, including a full text description.
   Following this are the arguments for <literal>exec1</literal> in
   blue.  A test class is a template that describes how a test runs; it
   is parameterized by [&fixme; xref] fields.  Each test provides
   [&fixme; xref] arguments for these fields, which determine what this
   specific tests does.</para>

   <para>The test class for test <literal>exec1</literal> is
   <classname>python.ExecTest</classname>.  Tests of this class are
   composed of two parts: a sequence of Python statements, and a Python
   expression.  When the test is run, &qmtest; executes the Python
   statements, and then evaluates the Python expression in the same
   context (so, for instance, variables defined in the statements can be
   referenced in the expression).  If the expression evaluates to a
   value Python considers to have a boolean true value, the test passes.
   For test <literal>exec1</literal>, the sequence of Python statements
   is simply the single statement <literal>pass</literal>, which in
   Python does nothing (this has nothing to do with the &qmtest; test
   outcome &PASS;).  The Python expression is "<literal>2
   + 2 == 5</literal>".  As Python is a sensible language, this
   expression obviously evaluates to some value which Python considers
   to be false (specificly, zero).  That's why the test fails.</para>

   <para>At the bottom of the test page, there are additional fields
   labelled "Prerequisite Tests" and "Resources."  These specify the
   relationship of this test with other tests and resources.  There is
   also a field labelled "Categories," which can be used as a further
   organizational tool.  You can ignore these fields for now.</para>

   <para>Shut down the &qmtest; GUI server by returning to the main page
   and clicking on the <guibutton>Shut Down</guibutton> button.</para>

  </section> <!-- sec-testtut-examining -->

  <section id="sec-testtut-expected-outcomes">
   <title>Expected Test Outcomes</title>

   <para>Let's re-run a test run including all the tests in the test
   database, this time writing the full results to a file,
   <filename>results.xml</filename>.</para>

   <screen>
&prompt;<userinput>qmtest run -o results.xml</userinput>
<computeroutput><![CDATA[
--- TEST RUN STATISTICS ------------------------------------------------------

       3        tests total

       2 ( 67%) tests PASS
       1 ( 33%) tests FAIL


--- TESTS THAT DID NOT PASS --------------------------------------------------

  exec1                                                          : FAIL    
      Expression evaluates to false.


]]></computeroutput></screen>

   <para>The full test results file contains the outcome (&PASS;,
   &FAIL;, etc.)  for each test that was run.  The result for each test
   may also contain additional properties, depending on the test
   class.</para>

   <para>&qmtest; allows you to specify expected outcomes for some or
   all of the tests in a test run.  Using expected outcomes, you may
   inform &qmtest; that you expect specific tests to fail.  Specify
   expected outcomes using the <option>&dashdash;outcomes</option> (or
   <option>-O</option>) option followed by the name of a file containing
   expected outcomes.  The format for an expected outcomes file is
   exactly the same as that of a test results file.  In fact, you may
   use a test results file as the expected outcomes for a subsequent
   test run; &qmtest; will report test results differing between the
   first run and the second.  Test result properties in the expected
   outcomes file, other than each test's outcome, are simply ignored.
   If there is no entry for a given test ID in the expected outcomes
   file, &qmtest; assumes the expected outcome is &PASS;.</para>

   <para>For example, to re-run all the tests in the test suite, using
   the previous results as expected outcomes, invoke &qmtest-cmd; like
   this:</para>

   <screen>
&prompt;<userinput>qmtest run -O results.xml .</userinput>
<computeroutput><![CDATA[
--- TEST RUN STATISTICS ------------------------------------------------------

       3        tests total

  Test results relative to expected outcomes:

       3 (100%) tests as expected

  Actual test results:

       2 ( 67%) tests PASS
       1 ( 33%) tests FAIL


--- TESTS THAT DID NOT PASS --------------------------------------------------

  exec1                                                          : FAIL    
      Expression evaluates to false.


]]></computeroutput></screen>

   <para>Now, even though one test fails, &qmtest; reports that 100% of
   tests produced outcomes as expected&mdash;the expected outcome for
   test <literal>exec1</literal> was &FAIL;, which matched its actual
   outcome.</para>

  </section> <!-- sec-testtut-expected-outcomes -->

  <section id="sec-testtut-modifying">
   <title>Modifying and Creating Tests</title>

   <para>Let's fix test <literal>exec1</literal> so it passes.</para>

   <para>Start the server again with the <command>&qmtest-cmd;
   server</command> command.  Click on the <guibutton>Edit</guibutton>
   button towards the upper-right corner of the page for test
   <literal>exec1</literal>.  &qmtest; shows a similar form, but now the
   values of arguments are editable.</para>

   <para>Change the second argument, labelled "Python Expression," to an
   expression that evaluates to a boolean true value, such as
   "<literal>2 + 3 == 5</literal>".  At the bottom of the form is an
   <guibutton>OK</guibutton> button; click on it to commit the changes.
   &qmtest; redisplays the test, now showing your updated Python
   expression.</para>

   <para>Now let's shut down the server and rerun the tests in the test
   database.  End the server by clicking on the <guibutton>Shut
   Down</guibutton> button on the main page, and resubmit the original
   test run:</para>

   <screen>
&prompt;<userinput>qmtest run</userinput>
<computeroutput><![CDATA[
--- TEST RUN STATISTICS ------------------------------------------------------

       3        tests total

       3 (100%) tests PASS

]]></computeroutput></screen>

   <para>Now all three tests pass.</para>

   <para>Creating a new test is no more difficult.  Start the GUI server
   again, and from the full listing page for the test database, click on
   the <guibutton>New Test</guibutton> button.  &qmtest; displays a page
   asking for the new test's ID and test class.  For the test ID, enter
   <literal>new.exec0</literal>.  For the test class, choose
   <classname>python.ExecTest</classname>, the same test class used for
   the test <literal>exec1</literal> we just edited.  Then click on the
   <guibutton>Next &gt;</guibutton> button, and &qmtest; shows you a
   page identical to the form for editing an existing test.</para>

   <para>&qmtest; provides default values for the arguments, which you
   can change.  Try replacing the statement <literal>pass</literal> with
   a variable assignment, such as <literal>x = 3</literal>.  Replace the
   expression "<literal>1</literal>" with a boolean expression involving
   <varname>x</varname>, one that is true, such as <literal>2 * x &lt;
   7</literal>.  Click on the <guibutton>OK</guibutton> button when you
   are done.</para>

   <para>You can try running your new test by specifying its test ID to
   <command>&qmtest-cmd; run</command>, or you can run all tests in the
   database, including your new test.</para>

  </section> <!-- sec-testtut-modifying -->


  <section id="sec-testtut-test-class">
   <title>Writing a Test Class</title>

   <para>&qmtest; includes several useful standard test classes, with
   which you can write a variety of useful tests.  However, for many
   applications you may need to write new test classes, or adapt
   existing test classes to suit your needs.  To do this requires a
   moderate facility with Python.</para>

   <para>A test class is represented by a Python class.  The Python
   class needs to have three specific attributes:</para>

   <itemizedlist>
    <listitem>
     <para>An attribute named <property>fields</property>.  This
     attribute is a declaration of the parameters to the test
     class.</para>

     <para>The parameters are represented by a sequence of objects, each
     an instance of some subclass of
     <classname>qm.fields.Field</classname>.  For example, a text-valued
     field is an instance of <classname>qm.fields.TextField</classname>,
     an integer-valued field is an instance of
     <classname>qm.fields.IntegerField</classname>, etc.  See &fixme;
     xref for details about these.</para>

     <para>The field names correspond to the argument names as
     specified in the test &xml; file.  In the
     <classname>Count</classname> example above, the field names are
     <property>input</property> and
     <property>expected_value</property>.</para>
    </listitem>

    <listitem>
     <para>An <function>__init__</function> function, which is used to
     instantiate the test as it is loaded from the test database.  The
     arguments to this function must have the same names as the names of
     the fields.</para>
    </listitem>

    <listitem>
     <para>A <function>Run</function> function.  This function is
     called with a single argument, an instance of
     <classname>qm.test.base.Context</classname>.  It should return an
     instance of <classname>qm.test.base.Result</classname>, indicating
     the test result.</para>
    </listitem>
   </itemizedlist>

   <para>The doc string of the Python class is used as the description
   for the test class in the user interface.  &qmtest; interprets it
   according to the usual Python structured text semantics [&fixme;
   xref].  Each field object may have an property named
   <varname>description</varname>, which serves an analogous role for
   fields of the test class.  Field objects may also have a property
   named <varname>title</varname>, which is a user-friendly title for
   the field that's shown in the user interface instead of the internal
   Python name.</para>

   <para>For example, let's write a simple test class named
   <classname>Count</classname>.  This test class counts the length of a
   string, and compares it to an expected length.  The string and the
   expected length are the arguments in each test of this test class,
   and the test passes if the length of the string matches the expected
   length.</para>

   <para>The Python file containing this test test class might look like
   this:</para>

   <programlisting><![CDATA[
import qm.fields
from   qm.test.base import Result

class Count:
    """Count the number of characters in a string.

    A 'Count' test counts up the number of characters in a string, given
    by the value of the "Input" field.  The test passes if the length
    matches the value of the "Expected Value" field."""

    fields = [
        qm.fields.TextField(
            name="input",
            title="Input",
            description="The input string."),

        qm.fields.IntegerField(
            name="expected_value",
            title="Expected Value",
            description="The expected length of the input string."),
        ]

    def __init__(self, input, expected_value):
        # Store the arguments for later.
        self.__input = input
        self.__expected_value = expected_value

    def Run(self, context):
        # Compute the length.
        length = len(self.__input)
        # Compare it to the expected value.
        if length == self.__expected_value:
            return Result(Result.PASS)
        else:
            return Result(Result.FAIL)
]]></programlisting>

   <para>Where should you place this file?  <xref
   linkend="sec-specifying-test-class"/> describes in detail how
   &qmtest; locates test classes.  Classes such as this one that are
   used only within a single test database are placed in a subdirectory
   named <filename>_classes</filename> in the test database directory.
   The tutorial database already includes a file containing the test
   class listed above; if you made a copy of the test database as
   described above, you should have a file
   <filename>~/tdb/_classes/count.py</filename>.  Since the test class
   <classname>Count</classname> is stored in the Python module file
   <filename>count.py</filename>, &qmtest; refers to the test class by
   the name <classname>count.Count</classname>.</para>

   <para>To create a test using this class, click on the <guibutton>New
   Test</guibutton> button on the full listing page, as before.  For the
   new test ID, enter <literal>new.count0</literal>.  Since
   <classname>count.Count</classname> is a custom class, its name does
   not appear in the list of standard test classes; you must enter it
   manually into the test class dialog box.  When you click on the
   <guibutton>Next &gt;</guibutton> button, &qmtest; shows you a form to
   edit the new test.  Note that the doc string for
   <classname>Count</classname> appears as the test class description,
   and the <varname>title</varname> and <varname>description</varname>
   properties of the two fields are listed next to controls for the two
   test arguments.  For the "Input" field, enter the string
   "<literal>Hello, world!</literal>".  For the "Expected Value" field,
   enter the value 13.  Click <guibutton>OK</guibutton>, and you should
   now be able to run the new test <literal>new.count0</literal>, which
   should pass.</para>

   <screen>
&prompt;<userinput>qmtest run new.count0</userinput>
<computeroutput><![CDATA[
--- TEST RUN STATISTICS ------------------------------------------------------

       1        tests total

       1 (100%) tests PASS

]]></computeroutput>
   </screen>

  </section> <!-- sec-testtut-test-class -->

<!--

   <section>
    <title>Provided Test Classes</title>

    <para>&qmtest; comes with a module <classname>command</classname>,
    which contains three test classes for testing command-line programs.</para>

    <itemizedlist>
     <listitem>
      <para>The <classname>command.ExecTest</classname> test class
      runs a program and compares its exit code, standard output, and
      standard error to expected values.  The program is invoked
      directly, without a command shell, and is passed command-line
      arguments specified in the test.  The test may also specify text
      or data to pass to the program as standard input.</para>
     </listitem>

     <listitem>
      <para>The <classname>command.CommandTest</classname> is similar
      to <classname>command.ExecText</classname>, but runs the program
      via a command shell.  The command shell's escaping and
      substitution rules apply to the executed command.</para>

      <para>Since command shell syntaxes vary across platforms, tests
      written using this test class are not in general portable.</para>
     </listitem>

     <listitem>
      <para>The <classname>command.ScriptTest</classname> extends this
      by running an entire shell script, rather than a single shell
      command.  All the features of the command shell are available in
      the script.</para>

      <para>As with <classname>command.CommandTest</classname>, tests
      written with this class are not in general portable.</para>
     </listitem>

     <listitem>
      <para>The <classname>python.ExecTest</classname> test class runs
      a test by executing Python code.  A test can include either or
      both of a sequence of Python statements, as in an ordinary
      Python script, and a Python expression.  If the expression is
      provided, the test passes if and only if the expression
      evaluates to a true value.</para>
     </listitem>

     <listitem>
      <para>The <classname>python.ExeceptionTest</classname> test
      class runs a test by executing a sequence of Python statements.
      The test passes if the statements raises an exception.
      Optionally, the exception type and arguments may be specified in
      the test; if so, the exception raised by the Python code must
      match these for the test to pass.</para>
     </listitem>
    </itemizedlist>

    <para>Here's an example of a test using the second of these.</para>

    <programlisting><![CDATA[
<?xml version="1.0"?>
<!DOCTYPE test PUBLIC "-//Software Carpentry//&qmtest; Test V0.1//EN" "">
<test>
 <class>command.CommandTest</class>
 <argument name="command">
  <text>uname</text>
 </argument>
 <argument name="exit_code">
  <integer>0</integer>
 </argument>
 <argument name="stdout">
  <attachment>
   <data>Linux
</data>
  </attachment>
 </argument>
 <argument name="stderr">
  <attachment>
   <data></data>
  </attachment>
 </argument>
</test>
]]></programlisting>

    <para>The command argment specifies the command to run, in this case
    <command>uname</command>.  The <property>exit_code</property>
    argument specifies the expected exit code, in this case zero.  The
    <property>stdout</property> and <property>stderr</property>
    arguments specify the expected output to the respective streams.  In
    this case, the expected standard output is
    "<literal>Linux</literal>" followed by a newline, while no text is
    expected on standard error.</para>

   </section>
-->

</chapter>
<!--
  Local Variables:
  mode: sgml
  indent-tabs-mode: nil
  sgml-indent-step: 1 
  sgml-always-quote-attributes: t
  sgml-general-insert-case: lower
  sgml-minimize-attributes: nil
  sgml-parent-document: ("manual.xml" "book" "chapter")
  End:
-->
